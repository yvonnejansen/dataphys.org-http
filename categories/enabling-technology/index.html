<!DOCTYPE html>
<html lang="en-us">
  <head>
    <meta charset="utf-8" />
<title>Enabling technology</title>


  
    
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-55415265-1"></script>
    <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());
    gtag('config', 'UA-55415265-1');
  </script>
  



<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1.0" />
<link
  rel="alternate"
  type="application/rss+xml"
  href="http://dataphys.org/list/index.xml"
  title="List of Physical Visualizations"
/>
<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Enabling technology"/>
<meta name="twitter:description" content=""/>



  <link rel="stylesheet" href="http://dataphys.org/list/css/style.css" />
  <link rel="preconnect" href="https://fonts.gstatic.com">
  <link href="https://fonts.googleapis.com/css2?family=Open+Sans:wght@300;400;600&display=swap" rel="stylesheet">

  </head>
  <body>
      <header>
    <div class="head">
      
      <a href="http://dataphys.org/list/">
        <center>
          List of Physical Visualizations<br />
      
        <div class="head2">and Related Artifacts</div>
      </center></a>
    </div>

  </header>
  


    
<div class="container">
    <div class="section">
        <div class="content">
            <center><div class="head_query">Enabling technology</div></center>
        </div>
        <div class="content-main content listview">
            
                <article class="entry-main post category-enabling-technology">
  <a href="http://dataphys.org/list/pop-up-and-movable-books/">
    <h1 class="post-title">1200 – Pop-Up and Movable Books</h1>
  </a>
  <div class="post-entry">
    <a href="http://dataphys.org/list/pop-up-and-movable-books/"><img class="list-view" width="170px" height="100px" src="http://dataphys.org/list/images/uploads/2018/04/parisvolvelle-170x100.jpg"></a>
    <div class="excerpt-listview">
      <p>
  
     While gatefold mechanisms were already used in the 1100s, one of the first movable paper mechanisms was a volvelle created by Benedictine Monk Matthew Paris to calculate the dates of Christian holidays in his book Chronica Majorca (1236-1253, see left image above). Volvelles are paper discs or rings placed on top of each other that rotate around a string or rivet. Many other types of paper mechanisms have been invented since then, such as flaps, which were used in anatomy books starting [&hellip;]</p>
    </div>
    <div class="hidden full-text">     While gatefold mechanisms were already used in the 1100s, one of the first movable paper mechanisms was a volvelle created by Benedictine Monk Matthew Paris to calculate the dates of Christian holidays in his book Chronica Majorca (1236-1253, see left image above). Volvelles are paper discs or rings placed on top of each other that rotate around a string or rivet. Many other types of paper mechanisms have been invented since then, such as flaps, which were used in anatomy books starting from the 16th century (see second image above, 17th century, and third image, undated). Only in the 19th century did movable books started to be used for entertainment purposes and for children.  Ellen G.K. Rubin (aka the pop-up lady) has a rich website and a must-watch talk about the history of pop-up and movable books.  For a modern example of a pop-up book used to convey data, see our entry 2013 - Pop-Up Infographics.  Sources:   Ellen G.K. Rubin, Pop-up Lady Website.   Mugdha Kale, Pop-Up Design.   E.D.W. Lynch (2011) Animated Anatomies, An Exhibition of Antique Medical Pop-Up Books. (with link to a video)   Left and middle image from popuplady.com, right image from laughingsquid.com.   </div>

  <div class="categories">
    <div class="categories tagi">
  Added by: <b>Pierre Dragicevic</b>, sent by: <b>Benjamin Bach</b>.
  
    Category:
    
      <a
        href="http://dataphys.org/list/categories/enabling-technology/"
        >Enabling technology</a
      >&nbsp;
    
  
  
    Tags:
    <a
        href="http://dataphys.org/list/tags/anatomy/"
        >anatomy</a>, <a
        href="http://dataphys.org/list/tags/book/"
        >book</a>, <a
        href="http://dataphys.org/list/tags/mechanical-interaction/"
        >mechanical interaction</a>, <a
        href="http://dataphys.org/list/tags/paper/"
        >paper</a>, <a
        href="http://dataphys.org/list/tags/pop-up/"
        >pop-up</a>
  
</div>

  </div><br><hr class="entry-main">
    </div>

</article>

            
                <article class="entry-main post category-enabling-technology">
  <a href="http://dataphys.org/list/stop-motion-animation/">
    <h1 class="post-title">1897 – Stop Motion Animation</h1>
  </a>
  <div class="post-entry">
    <a href="http://dataphys.org/list/stop-motion-animation/"><img class="list-view" width="170px" height="100px" src="http://dataphys.org/list/images/uploads/2018/04/humpty-170x100@2x.jpg"></a>
    <div class="excerpt-listview">
      <p>
  
    Stop motion animation is the frame-by-frame capture of (generally) inanimate objects which are manipulated by increments in order to produce the illusion of motion. It was first used in movies to produce magical effects. The first movie to use this technique was The Humpty Dumpty Circus (1897), where a toy circus of acrobats and animals comes to life (left image).  With modern 3D computer graphics, stop motion animation has become largely obsolete, but remains occasionally used. A [&hellip;]</p>
    </div>
    <div class="hidden full-text">    Stop motion animation is the frame-by-frame capture of (generally) inanimate objects which are manipulated by increments in order to produce the illusion of motion. It was first used in movies to produce magical effects. The first movie to use this technique was The Humpty Dumpty Circus (1897), where a toy circus of acrobats and animals comes to life (left image).  With modern 3D computer graphics, stop motion animation has become largely obsolete, but remains occasionally used. A particularly appealing example is the &#34;Bears on Stairs&#34; video made in 2014 by the creative agency DBLG (video on the right), where a computer model of a bear was 3D-printed in many different poses to create a surprisingly smooth stop motion animation.  For an example of how stop motion animation can be used for telling stories about data, see our entry 1965 - Stop Motion Animation of Physical 3D Map.  Sources:   Wikipedia, Stop Motion.   Burgett (2014) ‘Bears On Stairs’ Is a Ridiculously Smooth Stop Motion Animated Video.   Left image from youtube user teamrandom21. Right image from DBLG.   </div>

  <div class="categories">
    <div class="categories tagi">
  Added by: <b>Pierre Dragicevic</b>.
  
    Category:
    
      <a
        href="http://dataphys.org/list/categories/enabling-technology/"
        >Enabling technology</a
      >&nbsp;
    
  
  
    Tags:
    <a
        href="http://dataphys.org/list/tags/stop-motion-animation/"
        >stop motion animation</a>
  
</div>

  </div><br><hr class="entry-main">
    </div>

</article>

            
                <article class="entry-main post category-enabling-technology">
  <a href="http://dataphys.org/list/solid-terrain-modeling-techniques/">
    <h1 class="post-title">1900 – Modern Solid Terrain Modeling</h1>
  </a>
  <div class="post-entry">
    <a href="http://dataphys.org/list/solid-terrain-modeling-techniques/"><img class="list-view" width="170px" height="100px" src="http://dataphys.org/list/images/uploads/2014/10/Terrain_emboss-170x100@2x.jpg"></a>
    <div class="excerpt-listview">
      <p>
  
    The Institute of Cartography ETH Zurich published a great review of past and present techniques for doing solid terrain modeling. Although terrain models are not physical visualizations in the strict sense, the techniques could be in principle used to convey data. Physical terrain models were already being built in 16th the century, and the review covers modern techniques from the early 20th century to today&#39;s digital fabrication.  Source: Institute of Cartography ETH Zurich (2006) Terrain [&hellip;]</p>
    </div>
    <div class="hidden full-text">    The Institute of Cartography ETH Zurich published a great review of past and present techniques for doing solid terrain modeling. Although terrain models are not physical visualizations in the strict sense, the techniques could be in principle used to convey data. Physical terrain models were already being built in 16th the century, and the review covers modern techniques from the early 20th century to today&#39;s digital fabrication.  Source: Institute of Cartography ETH Zurich (2006) Terrain modeling website - Production techniques. </div>

  <div class="categories">
    <div class="categories tagi">
  Added by: <b>Pierre Dragicevic</b>.
  
    Category:
    
      <a
        href="http://dataphys.org/list/categories/enabling-technology/"
        >Enabling technology</a
      >&nbsp;
    
  
  
    Tags:
    <a
        href="http://dataphys.org/list/tags/cartographic/"
        >cartographic</a>, <a
        href="http://dataphys.org/list/tags/cartography/"
        >cartography</a>, <a
        href="http://dataphys.org/list/tags/terrain-model/"
        >terrain model</a>, <a
        href="http://dataphys.org/list/tags/terrain-modeling/"
        >terrain modeling</a>
  
</div>

  </div><br><hr class="entry-main">
    </div>

</article>

            
                <article class="entry-main post category-enabling-technology">
  <a href="http://dataphys.org/list/charles-csuris-numeric-milling-sculpture/">
    <h1 class="post-title">1968 – Charles Csuri&#39;s Numeric Milling Sculpture</h1>
  </a>
  <div class="post-entry">
    <a href="http://dataphys.org/list/charles-csuris-numeric-milling-sculpture/"><img class="list-view" width="170px" height="100px" src="http://dataphys.org/list/images/uploads/2014/11/CsuriSculpture_68and_Hand-170x100@2x.jpg"></a>
    <div class="excerpt-listview">
      <p>
  
     Csuri&#39;s wooden sculpture Numeric Milling is one of the few early computer sculptures created with a computer-driven milling machine... This work made use of the Bessel function to generate the surface. The computer program then generated a punched tape to represent the coordinate data. Included were instructions to a 3-axis, continuous path, numerically controlled milling machine.   Sources:   Csuri Project: Plotter Drawing, 1966 - 1970: Numeric Milling   Photo of Numeric Milling Sculpture [&hellip;]</p>
    </div>
    <div class="hidden full-text">     Csuri&#39;s wooden sculpture Numeric Milling is one of the few early computer sculptures created with a computer-driven milling machine... This work made use of the Bessel function to generate the surface. The computer program then generated a punched tape to represent the coordinate data. Included were instructions to a 3-axis, continuous path, numerically controlled milling machine.   Sources:   Csuri Project: Plotter Drawing, 1966 - 1970: Numeric Milling   Photo of Numeric Milling Sculpture courtesy of Charles Csuri    </div>

  <div class="categories">
    <div class="categories tagi">
  Added by: <b>Matthew Lewis</b>.
  
    Category:
    
      <a
        href="http://dataphys.org/list/categories/enabling-technology/"
        >Enabling technology</a
      >&nbsp;
    
  
  
    Tags:
    <a
        href="http://dataphys.org/list/tags/digital-fabrication/"
        >digital fabrication</a>, <a
        href="http://dataphys.org/list/tags/mathematical-functions/"
        >mathematical functions</a>, <a
        href="http://dataphys.org/list/tags/milling/"
        >milling</a>, <a
        href="http://dataphys.org/list/tags/punch-cards/"
        >punch cards</a>, <a
        href="http://dataphys.org/list/tags/wood/"
        >wood</a>
  
</div>

  </div><br><hr class="entry-main">
    </div>

</article>

            
                <article class="entry-main post category-enabling-technology">
  <a href="http://dataphys.org/list/byrons-bender/">
    <h1 class="post-title">1970 – Byron&#39;s Bender</h1>
  </a>
  <div class="post-entry">
    <a href="http://dataphys.org/list/byrons-bender/"><img class="list-view" width="170px" height="100px" src="http://dataphys.org/list/images/uploads/2015/11/about-170x100@2x.jpg"></a>
    <div class="excerpt-listview">
      <p>
  
    In the early 1970&#39;s, crystallographer Byron Rubin invented a tool that bends wires to make proteins models. The tool was popular until the 1990s. Byron Rubin became an artist who builds large-scale molecular sculptures.  Eric Martz and Eric Francoeur explain how such physical models yielded important scientific insights:   An example illustrating the importance of models from Byron&#39;s Bender occurred at a scientific meeting in the mid 1970&#39;s. At this time, less than two dozen protein [&hellip;]</p>
    </div>
    <div class="hidden full-text">    In the early 1970&#39;s, crystallographer Byron Rubin invented a tool that bends wires to make proteins models. The tool was popular until the 1990s. Byron Rubin became an artist who builds large-scale molecular sculptures.  Eric Martz and Eric Francoeur explain how such physical models yielded important scientific insights:   An example illustrating the importance of models from Byron&#39;s Bender occurred at a scientific meeting in the mid 1970&#39;s. At this time, less than two dozen protein structures had been solved. David Davies brought a Bender model of an immunoglobulin Fab fragment, and Jane and David Richardson brought a Bender model of superoxide dismutase. While comparing these physical models at the meeting, they realized that both proteins use a similar fold, despite having only about 9% sequence identity. This incident was the first recognition of the occurrence of what is now recognized as the immunoglobulin superfamily domain in proteins that are apparently unrelated by sequence. The insight was published in a paper entitled &#34;Similarity of three-dimensional structure between the immunoglobulin domain and the copper, zinc superoxide dismutase subunit&#34; ( Richardson et al., J. Mol. Biol. 102:221-235, 1976).   Also see the more recent DIWire device by Pensalabs.  Sources:   Byron Rubin. molecularsculpture.com.   Eric Martz and Eric Francoeur (1997-2004) History of Visualization of Biological Macromolecules.   Left image from molecularsculpture.com. Right image from The Journal of Biocommunication.   </div>

  <div class="categories">
    <div class="categories tagi">
  Added by: <b>Pierre Dragicevic</b>.
  
    Category:
    
      <a
        href="http://dataphys.org/list/categories/enabling-technology/"
        >Enabling technology</a
      >&nbsp;
    
  
  
    Tags:
    <a
        href="http://dataphys.org/list/tags/chemistry/"
        >chemistry</a>, <a
        href="http://dataphys.org/list/tags/molecule/"
        >molecule</a>, <a
        href="http://dataphys.org/list/tags/protein/"
        >protein</a>, <a
        href="http://dataphys.org/list/tags/science/"
        >science</a>, <a
        href="http://dataphys.org/list/tags/wire-bender/"
        >wire bender</a>
  
</div>

  </div><br><hr class="entry-main">
    </div>

</article>

            
                <article class="entry-main post category-enabling-technology">
  <a href="http://dataphys.org/list/graphical-waterfall/">
    <h1 class="post-title">1977 – Graphical Waterfall</h1>
  </a>
  <div class="post-entry">
    <a href="http://dataphys.org/list/graphical-waterfall/"><img class="list-view" width="170px" height="100px" src="http://dataphys.org/list/images/uploads/2018/07/graphical-waterfall-170x100@2x.png"></a>
    <div class="excerpt-listview">
      <p>
  
 &nbsp;&nbsp;  A&nbsp;graphical waterfall is a display where&nbsp;images are formed by water droplets falling from computer-controlled nozzles. It was invented in 1977 by&nbsp;Stephen Pevnick, an American artist. Graphical waterfalls can be used with regular&nbsp;lighting (as on the left video) or with a stroboscope (as on the right video), depending on the desired effect. It is unclear whether such devices have been already used to display data.  Sources:   Pevnick Design (2018),&nbsp;Invention [&hellip;]</p>
    </div>
    <div class="hidden full-text"> &amp;nbsp;&amp;nbsp;  A&amp;nbsp;graphical waterfall is a display where&amp;nbsp;images are formed by water droplets falling from computer-controlled nozzles. It was invented in 1977 by&amp;nbsp;Stephen Pevnick, an American artist. Graphical waterfalls can be used with regular&amp;nbsp;lighting (as on the left video) or with a stroboscope (as on the right video), depending on the desired effect. It is unclear whether such devices have been already used to display data.  Sources:   Pevnick Design (2018),&amp;nbsp;Invention of the Graphical Waterfall&amp;reg;.   Wikipedia, Stephen Pevnick.   </div>

  <div class="categories">
    <div class="categories tagi">
  Added by: <b>Pierre Dragicevic</b>.
  
    Category:
    
      <a
        href="http://dataphys.org/list/categories/enabling-technology/"
        >Enabling technology</a
      >&nbsp;
    
  
  
    Tags:
    <a
        href="http://dataphys.org/list/tags/display/"
        >display</a>, <a
        href="http://dataphys.org/list/tags/water/"
        >water</a>
  
</div>

  </div><br><hr class="entry-main">
    </div>

</article>

            
                <article class="entry-main post category-enabling-technology">
  <a href="http://dataphys.org/list/a-shape-display-appears-in-a-movie/">
    <h1 class="post-title">2000 – A Shape Display Appears in a Movie</h1>
  </a>
  <div class="post-entry">
    <a href="http://dataphys.org/list/a-shape-display-appears-in-a-movie/"><img class="list-view" width="170px" height="100px" src="http://dataphys.org/list/images/uploads/2015/02/x-men-brighter-170x100@2x.png"></a>
    <div class="excerpt-listview">
      <p>
  
    An imaginary ultra high-resolution 2.5D shape display appears in the 2000 movie X-Men. The rendering and animations are visually quite appealing. Notice how impossible overhangs appear at 0:27 (the bridge) and 0:33 (the torch of the Statue of Liberty).  This movie scene has prompted a company to design and build an actuated solid terrain model for military customers, see our entry 2004 – XenoVision Mark III. Also see our entry 2009 – Leithinger’s Interactive Shape Displays for a much [&hellip;]</p>
    </div>
    <div class="hidden full-text">    An imaginary ultra high-resolution 2.5D shape display appears in the 2000 movie X-Men. The rendering and animations are visually quite appealing. Notice how impossible overhangs appear at 0:27 (the bridge) and 0:33 (the torch of the Statue of Liberty).  This movie scene has prompted a company to design and build an actuated solid terrain model for military customers, see our entry 2004 – XenoVision Mark III. Also see our entry 2009 – Leithinger’s Interactive Shape Displays for a much lower-resolution but ultra fast and highly interactive version.  Source: 20th Century Fox (2000) X-Men. </div>

  <div class="categories">
    <div class="categories tagi">
  Added by: <b>Pierre Dragicevic</b>.
  
    Category:
    
      <a
        href="http://dataphys.org/list/categories/enabling-technology/"
        >Enabling technology</a
      >&nbsp;
    
  
  
    Tags:
    <a
        href="http://dataphys.org/list/tags/cartographic/"
        >cartographic</a>, <a
        href="http://dataphys.org/list/tags/movie/"
        >movie</a>, <a
        href="http://dataphys.org/list/tags/pop-culture/"
        >pop culture</a>, <a
        href="http://dataphys.org/list/tags/sci-fi/"
        >sci-fi</a>, <a
        href="http://dataphys.org/list/tags/shape-display/"
        >shape display</a>
  
</div>

  </div><br><hr class="entry-main">
    </div>

</article>

            
                <article class="entry-main post category-enabling-technology">
  <a href="http://dataphys.org/list/graph-board/">
    <h1 class="post-title">2000 – Graph Boards</h1>
  </a>
  <div class="post-entry">
    <a href="http://dataphys.org/list/graph-board/"><img class="list-view" width="170px" height="100px" src="http://dataphys.org/list/images/uploads/2014/10/blind3-170x100@2x.png"></a>
    <div class="excerpt-listview">
      <p>
  
    Mathematics and geometry are often taught to blind students using a cork board with raised grid lines, push pins and rubber bands. The right image shows a teacher explaining the use of the Graphic Aid for Mathematics, a physical kit sold by the American Printing House for the Blind.  Date of invention unknown.  Sources:   Suzan Osterhaus (2001) Teaching Math to Visually Impaired Students.   Youtube video series explaining the traditional cork board: APH Graph Board with Susan Osterhaus. [&hellip;]</p>
    </div>
    <div class="hidden full-text">    Mathematics and geometry are often taught to blind students using a cork board with raised grid lines, push pins and rubber bands. The right image shows a teacher explaining the use of the Graphic Aid for Mathematics, a physical kit sold by the American Printing House for the Blind.  Date of invention unknown.  Sources:   Suzan Osterhaus (2001) Teaching Math to Visually Impaired Students.   Youtube video series explaining the traditional cork board: APH Graph Board with Susan Osterhaus.   McGookin et al. (2010) Clutching at Straws: Using Tangible Interaction to Provide Non-Visual Access to Graphs.   </div>

  <div class="categories">
    <div class="categories tagi">
  Added by: <b>Pierre Dragicevic</b>.
  
    Category:
    
      <a
        href="http://dataphys.org/list/categories/enabling-technology/"
        >Enabling technology</a
      >&nbsp;
    
  
  
    Tags:
    <a
        href="http://dataphys.org/list/tags/blind/"
        >blind</a>, <a
        href="http://dataphys.org/list/tags/pin-board/"
        >pin board</a>
  
</div>

  </div><br><hr class="entry-main">
    </div>

</article>

            
                <article class="entry-main post category-enabling-technology">
  <a href="http://dataphys.org/list/xenovision-mark-iii-a-dynamic-solid-terrain-model/">
    <h1 class="post-title">2004 – XenoVision Mark III: A Dynamic Solid Terrain Model</h1>
  </a>
  <div class="post-entry">
    <a href="http://dataphys.org/list/xenovision-mark-iii-a-dynamic-solid-terrain-model/"><img class="list-view" width="170px" height="100px" src="http://dataphys.org/list/images/uploads/2014/11/Xenovision-170x100@2x.gif"></a>
    <div class="excerpt-listview">
      <p>
  
     The XenoVision Mark III Dynamic Sand Table by the company Xenotran is a self-reconfigurable solid terrain model with military applications. There is little information on this device but it seems well ahead of its time. Michael Schmitz and coauthors explain how this high-resolution shape display with 7000 actuators was originally inspired by a scene from the X-Men movie (see our entry 2000 – A Shape Display Appears in a Movie).  Sources:   Directions Magazine (2004) Interview with Xenotran [&hellip;]</p>
    </div>
    <div class="hidden full-text">     The XenoVision Mark III Dynamic Sand Table by the company Xenotran is a self-reconfigurable solid terrain model with military applications. There is little information on this device but it seems well ahead of its time. Michael Schmitz and coauthors explain how this high-resolution shape display with 7000 actuators was originally inspired by a scene from the X-Men movie (see our entry 2000 – A Shape Display Appears in a Movie).  Sources:   Directions Magazine (2004) Interview with Xenotran Founder, Dr.Derrick Page.   Images by Xenotran.   </div>

  <div class="categories">
    <div class="categories tagi">
  Added by: <b>Pierre Dragicevic</b>.
  
    Category:
    
      <a
        href="http://dataphys.org/list/categories/enabling-technology/"
        >Enabling technology</a
      >&nbsp;
    
  
  
    Tags:
    <a
        href="http://dataphys.org/list/tags/cartographic/"
        >cartographic</a>, <a
        href="http://dataphys.org/list/tags/military/"
        >military</a>, <a
        href="http://dataphys.org/list/tags/movie/"
        >movie</a>, <a
        href="http://dataphys.org/list/tags/solid-terrain-model/"
        >solid terrain model</a>
  
</div>

  </div><br><hr class="entry-main">
    </div>

</article>

            
                <article class="entry-main post category-enabling-technology">
  <a href="http://dataphys.org/list/bmw-kinetic-sculpture/">
    <h1 class="post-title">2008 – BMW Kinetic Sculpture</h1>
  </a>
  <div class="post-entry">
    <a href="http://dataphys.org/list/bmw-kinetic-sculpture/"><img class="list-view" width="170px" height="100px" src="http://dataphys.org/list/images/uploads/2014/11/kinetik_main_06-170x100@2x.jpg"></a>
    <div class="excerpt-listview">
      <p>
  
     The Kinetic Sculpture is a metaphorical translation of the process of form-finding in art and design. 714 metal spheres, hanging from thin steel wires attached to individually-controlled stepper motors and covering the area of six square meters, animate a seven minute long mechatronic narrative. In the beginning, moving chaotically, then evolving to several competing forms that eventually resolve to the finished object, the kinetic sculpture creates an artistic visualisation of the process [&hellip;]</p>
    </div>
    <div class="hidden full-text">     The Kinetic Sculpture is a metaphorical translation of the process of form-finding in art and design. 714 metal spheres, hanging from thin steel wires attached to individually-controlled stepper motors and covering the area of six square meters, animate a seven minute long mechatronic narrative. In the beginning, moving chaotically, then evolving to several competing forms that eventually resolve to the finished object, the kinetic sculpture creates an artistic visualisation of the process of form-finding in different variations.   Source: Art&#43;Com. Kinetic Scultpture (2008) </div>

  <div class="categories">
    <div class="categories tagi">
  Added by: <b>Yvonne Jansen</b>.
  
    Category:
    
      <a
        href="http://dataphys.org/list/categories/enabling-technology/"
        >Enabling technology</a
      >&nbsp;
    
  
  
    Tags:
    <a
        href="http://dataphys.org/list/tags/3d/"
        >3D</a>, <a
        href="http://dataphys.org/list/tags/data-sculpture/"
        >data sculpture</a>, <a
        href="http://dataphys.org/list/tags/self-actuated/"
        >self-actuated</a>
  
</div>

  </div><br><hr class="entry-main">
    </div>

</article>

            
                <article class="entry-main post category-enabling-technology">
  <a href="http://dataphys.org/list/irregular-cake-mold/">
    <h1 class="post-title">2009 – S-XL CAKE: Irregular Cake Mold</h1>
  </a>
  <div class="post-entry">
    <a href="http://dataphys.org/list/irregular-cake-mold/"><img class="list-view" width="170px" height="100px" src="http://dataphys.org/list/images/uploads/2014/10/1e8edf7ba2-170x100@2x.jpg"></a>
    <div class="excerpt-listview">
      <p>
  
   A cake mold that creates pieces of cake in different sizes. Although not a physical visualization, it could in principle encode data.  Source: Ding 3000 via Infosthetics.com. </p>
    </div>
    <div class="hidden full-text">   A cake mold that creates pieces of cake in different sizes. Although not a physical visualization, it could in principle encode data.  Source: Ding 3000 via Infosthetics.com. </div>

  <div class="categories">
    <div class="categories tagi">
  Added by: <b>Yvonne Jansen</b>.
  
    Category:
    
      <a
        href="http://dataphys.org/list/categories/enabling-technology/"
        >Enabling technology</a
      >&nbsp;
    
  
  
    Tags:
    <a
        href="http://dataphys.org/list/tags/food/"
        >food</a>, <a
        href="http://dataphys.org/list/tags/pie-chart/"
        >pie chart</a>
  
</div>

  </div><br><hr class="entry-main">
    </div>

</article>

            
                <article class="entry-main post category-enabling-technology">
  <a href="http://dataphys.org/list/shanghai-spheres/">
    <h1 class="post-title">2010 – Shanghai Spheres</h1>
  </a>
  <div class="post-entry">
    <a href="http://dataphys.org/list/shanghai-spheres/"><img class="list-view" width="170px" height="100px" src="http://dataphys.org/list/images/uploads/2014/11/Shanghai-Spheres-Kinetic-Sculpture-2-feeldesain-170x100@2x.jpg"></a>
    <div class="excerpt-listview">
      <p>
  
    For the 2010 World Expo at Shangai, Japanese firms ADK and Murayama and Las-Vegas firm Fisher Technical Services, Inc. created an array of 1,008 15cm diameter actuated spheres, each suspended by its own micro winch. The show does not include data visualizations.  Kinetic sculptures made of arrays of suspended spheres abound. An early one is Joe Gilbertson&#39;s (2007). More recent ones include Kinetic Rain (2012) and Triptych (2014). Also check BMW&#39;s Kinetic Sculpture (2008) on this list. [&hellip;]</p>
    </div>
    <div class="hidden full-text">    For the 2010 World Expo at Shangai, Japanese firms ADK and Murayama and Las-Vegas firm Fisher Technical Services, Inc. created an array of 1,008 15cm diameter actuated spheres, each suspended by its own micro winch. The show does not include data visualizations.  Kinetic sculptures made of arrays of suspended spheres abound. An early one is Joe Gilbertson&#39;s (2007). More recent ones include Kinetic Rain (2012) and Triptych (2014). Also check BMW&#39;s Kinetic Sculpture (2008) on this list.  Source: taittowers.com. </div>

  <div class="categories">
    <div class="categories tagi">
  Added by: <b>Pierre Dragicevic</b>.
  
    Category:
    
      <a
        href="http://dataphys.org/list/categories/enabling-technology/"
        >Enabling technology</a
      >&nbsp;
    
  
  
    Tags:
    <a
        href="http://dataphys.org/list/tags/large-scale/"
        >large-scale</a>, <a
        href="http://dataphys.org/list/tags/self-actuated/"
        >self-actuated</a>, <a
        href="http://dataphys.org/list/tags/shape-display/"
        >shape display</a>
  
</div>

  </div><br><hr class="entry-main">
    </div>

</article>

            
                <article class="entry-main post category-enabling-technology">
  <a href="http://dataphys.org/list/headspace-array-of-actuated-bars/">
    <h1 class="post-title">2010 – Headspace: Array of Actuated Bars</h1>
  </a>
  <div class="post-entry">
    <a href="http://dataphys.org/list/headspace-array-of-actuated-bars/"><img class="list-view" width="170px" height="100px" src="http://dataphys.org/list/images/uploads/2014/10/headspace-170x100@2x.jpg"></a>
    <div class="excerpt-listview">
      <p>
  
    Artist Geoffrey Drake-Brockman created Headspace, a matrix of 256 motorized bars (total size 150 x 150 x 80cm) to display the faces of over 700 schoolchildren. Not a data visualization, but could be used as such.  Source: Geoffrey Drake-Brockman (2010). http://www.drake-brockman.com.au/ </p>
    </div>
    <div class="hidden full-text">    Artist Geoffrey Drake-Brockman created Headspace, a matrix of 256 motorized bars (total size 150 x 150 x 80cm) to display the faces of over 700 schoolchildren. Not a data visualization, but could be used as such.  Source: Geoffrey Drake-Brockman (2010). http://www.drake-brockman.com.au/ </div>

  <div class="categories">
    <div class="categories tagi">
  Added by: <b>Pierre Dragicevic</b>.
  
    Category:
    
      <a
        href="http://dataphys.org/list/categories/enabling-technology/"
        >Enabling technology</a
      >&nbsp;
    
  
  
    Tags:
    <a
        href="http://dataphys.org/list/tags/shape-display/"
        >shape display</a>
  
</div>

  </div><br><hr class="entry-main">
    </div>

</article>

            
                <article class="entry-main post category-enabling-technology">
  <a href="http://dataphys.org/list/paper-models-of-3d-plots/">
    <h1 class="post-title">2011 – Paper Models of 3D Plots</h1>
  </a>
  <div class="post-entry">
    <a href="http://dataphys.org/list/paper-models-of-3d-plots/"><img class="list-view" width="170px" height="100px" src="http://dataphys.org/list/images/uploads/2020/05/3dplot-170x100@2x.jpg"></a>
    <div class="excerpt-listview">
      <p>
  
   Paul DeMarco from Maplesoft explains how to slice up 3D plots to build solid paper models.  Source: Mapleprimes </p>
    </div>
    <div class="hidden full-text">   Paul DeMarco from Maplesoft explains how to slice up 3D plots to build solid paper models.  Source: Mapleprimes </div>

  <div class="categories">
    <div class="categories tagi">
  Added by: <b>Pierre Dragicevic</b>.
  
    Category:
    
      <a
        href="http://dataphys.org/list/categories/enabling-technology/"
        >Enabling technology</a
      >&nbsp;
    
  
  
    Tags:
    <a
        href="http://dataphys.org/list/tags/mathematics/"
        >mathematics</a>, <a
        href="http://dataphys.org/list/tags/paper/"
        >paper</a>
  
</div>

  </div><br><hr class="entry-main">
    </div>

</article>

            
                <article class="entry-main post category-enabling-technology">
  <a href="http://dataphys.org/list/a-soft-and-transparent-handleable-protein-model/">
    <h1 class="post-title">2012 – A Soft and Transparent Handleable Protein Model</h1>
  </a>
  <div class="post-entry">
    <a href="http://dataphys.org/list/a-soft-and-transparent-handleable-protein-model/"><img class="list-view" width="170px" height="100px" src="http://dataphys.org/list/images/uploads/2020/06/soft-protein-170x100@2x.jpeg"></a>
    <div class="excerpt-listview">
      <p>
  
     This report demonstrates the viability of a new handleable protein molecular model with a soft and transparent silicone body similar to the molecule’s surface. A full-color printed main chain structure embedded in the silicone body enables users to simultaneously feel the molecular surface, view through the main chain structure, and manually simulate molecular docking. The interactive, hands-on experience deepens the user’s intuitive understanding of the complicated 3D protein structure and [&hellip;]</p>
    </div>
    <div class="hidden full-text">     This report demonstrates the viability of a new handleable protein molecular model with a soft and transparent silicone body similar to the molecule’s surface. A full-color printed main chain structure embedded in the silicone body enables users to simultaneously feel the molecular surface, view through the main chain structure, and manually simulate molecular docking. The interactive, hands-on experience deepens the user’s intuitive understanding of the complicated 3D protein structure and elucidates ligand binding and protein–protein interactions.   Also see our entry 2004 – Scripps’ Molecule Models or all our entries on chemistry.  Sources:   Masaru Kawakamia (2012) A soft and transparent handleable protein model.   TCT Magazine (2012) Transparent, handleable 3D printed molecular models.   Left photo by Masaru Kawakami, published by TCT Magazine.   </div>

  <div class="categories">
    <div class="categories tagi">
  Added by: <b>Pierre Dragicevic</b>, sent by: <b>Fanny Chevalier</b>.
  
    Category:
    
      <a
        href="http://dataphys.org/list/categories/enabling-technology/"
        >Enabling technology</a
      >&nbsp;
    
  
  
    Tags:
    <a
        href="http://dataphys.org/list/tags/3d-printing/"
        >3d printing</a>, <a
        href="http://dataphys.org/list/tags/chemistry/"
        >chemistry</a>, <a
        href="http://dataphys.org/list/tags/proteine-model/"
        >proteine model</a>
  
</div>

  </div><br><hr class="entry-main">
    </div>

</article>

            
                <article class="entry-main post category-enabling-technology">
  <a href="http://dataphys.org/list/large-scale-drone-swarm/">
    <h1 class="post-title">2012 – Large-Scale Drone Swarm</h1>
  </a>
  <div class="post-entry">
    <a href="http://dataphys.org/list/large-scale-drone-swarm/"><img class="list-view" width="170px" height="100px" src="http://dataphys.org/list/images/uploads/2014/11/49-Quadrocopters_4-620x325-170x100@2x.jpg"></a>
    <div class="excerpt-listview">
      <p>
  
    Floating spheres again, but this time there is no wire. An outdoor demonstration of 49 quadrocopters in a synchronized motion, by Ars Electronica Futurelab and Ascending Technologies GmbH.  Sources:   The Blaze (2012)   Also watch another demonstration involving 20 small quadrocopters indoors by the GRASP Lab at the University of Pennsylvania (2012).   </p>
    </div>
    <div class="hidden full-text">    Floating spheres again, but this time there is no wire. An outdoor demonstration of 49 quadrocopters in a synchronized motion, by Ars Electronica Futurelab and Ascending Technologies GmbH.  Sources:   The Blaze (2012)   Also watch another demonstration involving 20 small quadrocopters indoors by the GRASP Lab at the University of Pennsylvania (2012).   </div>

  <div class="categories">
    <div class="categories tagi">
  Added by: <b>Pierre Dragicevic</b>.
  
    Category:
    
      <a
        href="http://dataphys.org/list/categories/enabling-technology/"
        >Enabling technology</a
      >&nbsp;
    
  
  
    Tags:
    <a
        href="http://dataphys.org/list/tags/drones/"
        >drones</a>, <a
        href="http://dataphys.org/list/tags/quadrocopters/"
        >quadrocopters</a>
  
</div>

  </div><br><hr class="entry-main">
    </div>

</article>

            
                <article class="entry-main post category-enabling-technology">
  <a href="http://dataphys.org/list/hypermatrix-animated-matrix-walls/">
    <h1 class="post-title">2012 – Hypermatrix: Animated Matrix-Walls</h1>
  </a>
  <div class="post-entry">
    <a href="http://dataphys.org/list/hypermatrix-animated-matrix-walls/"><img class="list-view" width="170px" height="100px" src="http://dataphys.org/list/images/uploads/2014/11/portfolio_hypermatrix_pic_11-170x100@2x.jpg"></a>
    <div class="excerpt-listview">
      <p>
  
    2012 Yeosu EXPO HYUNDAI MOTOR GROUP created by media artist group : Jonpasang.   Hyper-Matrix is a kinetic landscape installation created for the Hyundai Motor Group Exhibition Pavilion in Korea, the 2012 Yeosu EXPO site. The installation consists of a specially made huge steel construction to support thousands of stepper motors that control 320x320mm cubes that project out of the internal facade of the building. The foam cubes are mounted to actuators that move them forward and back by the [&hellip;]</p>
    </div>
    <div class="hidden full-text">    2012 Yeosu EXPO HYUNDAI MOTOR GROUP created by media artist group : Jonpasang.   Hyper-Matrix is a kinetic landscape installation created for the Hyundai Motor Group Exhibition Pavilion in Korea, the 2012 Yeosu EXPO site. The installation consists of a specially made huge steel construction to support thousands of stepper motors that control 320x320mm cubes that project out of the internal facade of the building. The foam cubes are mounted to actuators that move them forward and back by the steppers, creating patterns across the three-sided display. Comprised of what at first appear to be three blank white walls, Hyper-Matrix installation quickly comes to life as thousands of individual cubic units forming a field of pixels begin to move, pulsate, and form dynamic images across the room, creating infinite number of possibilities in the vertical, 180 degree, landscape. In addition, as the boxes are arranged at only 5mm narrow intervals, the wall can also be a nice moving screen for the images projected on to it.   Source: Jonpasang, Hypermatrix. </div>

  <div class="categories">
    <div class="categories tagi">
  Added by: <b>Yvonne Jansen</b>.
  
    Category:
    
      <a
        href="http://dataphys.org/list/categories/enabling-technology/"
        >Enabling technology</a
      >&nbsp;
    
  
  
    Tags:
    <a
        href="http://dataphys.org/list/tags/data-sculpture/"
        >data sculpture</a>, <a
        href="http://dataphys.org/list/tags/exhibition/"
        >exhibition</a>
  
</div>

  </div><br><hr class="entry-main">
    </div>

</article>

            
                <article class="entry-main post category-enabling-technology">
  <a href="http://dataphys.org/list/programmable-matter-stars-in-a-movie/">
    <h1 class="post-title">2013 – Programmable Matter Stars in a Movie</h1>
  </a>
  <div class="post-entry">
    <a href="http://dataphys.org/list/programmable-matter-stars-in-a-movie/"><img class="list-view" width="170px" height="100px" src="http://dataphys.org/list/images/uploads/2015/02/liquid-geo-170x100@2x.png"></a>
    <div class="excerpt-listview">
      <p>
  
    Programmable matter with levitation capabilities is a key visual element in the 2013 movie Man of Steel. The (slowed down) segment above reveals what appears to be a 3D node-link diagram. This display technology is employed by an advanced civilization on Krypton and is referred to as Liquid Geometry or Liquid Geo by the movie team. Visual effects supervisor Dan Lemmon explains that it consists in:   a bunch of silver beads that are suspended through a magnetic field, and the machine is able [&hellip;]</p>
    </div>
    <div class="hidden full-text">    Programmable matter with levitation capabilities is a key visual element in the 2013 movie Man of Steel. The (slowed down) segment above reveals what appears to be a 3D node-link diagram. This display technology is employed by an advanced civilization on Krypton and is referred to as Liquid Geometry or Liquid Geo by the movie team. Visual effects supervisor Dan Lemmon explains that it consists in:   a bunch of silver beads that are suspended through a magnetic field, and the machine is able to control that magnetic field so that the collection of beads behave almost like three-dimensional pixels, and they can create a surface that floats in the air and describes whatever the thing is you’re supposed to be seeing.   Senior visual effects supervisor Joe Letteri clarifies the intent:   This stems from an idea that Zack Snyder [the movie director] had. He wanted to do something that was interesting and different in the way you saw the information presented. He didn&#39;t want to do just a typical screen. So one of the ideas that Zack had was to make it a little bit more tactile. The shapes really need to transform. You need something that has that look but has to be in a sense more liquid. [...] They had this sort of metallic, liquid droplet kind of feel, but it felt tactile.   Ironically, although liquid geo was designed to &#34;feel tactile&#34;, no one ever touches it in the movie. One might also wonder why Kryptonians appear to be stuck with monochrome rendering. Nevertheless, Man of Steel significantly departs from sci-fi stereotypes featuring either flat displays or disembodied holograms. Computer representations become both three-dimensional and tangible, and most importantly, they reflect natural light. Are we finally reaching the end of antiquated sci-fi aesthetics inspired from the Tron movie?  Sources:   Warner Bros. Pictures (2013) Man of Steel.   Wired (2013). Extra-Special Effects: The New Tech That Brought Krypton to Life in Man of Steel.   Wikipedia article on Man of Steel.   Also see our entry on programmable matter.   </div>

  <div class="categories">
    <div class="categories tagi">
  Added by: <b>Pierre Dragicevic</b>.
  
    Category:
    
      <a
        href="http://dataphys.org/list/categories/enabling-technology/"
        >Enabling technology</a
      >&nbsp;
    
  
  
    Tags:
    <a
        href="http://dataphys.org/list/tags/movie/"
        >movie</a>, <a
        href="http://dataphys.org/list/tags/network/"
        >network</a>, <a
        href="http://dataphys.org/list/tags/pop-culture/"
        >pop culture</a>, <a
        href="http://dataphys.org/list/tags/programmable-matter/"
        >programmable matter</a>, <a
        href="http://dataphys.org/list/tags/sci-fi/"
        >sci-fi</a>
  
</div>

  </div><br><hr class="entry-main">
    </div>

</article>

            
                <article class="entry-main post category-enabling-technology">
  <a href="http://dataphys.org/list/quickly-authoring-physical-visualizations/">
    <h1 class="post-title">2013 – Quickly Authoring Physical Visualizations</h1>
  </a>
  <div class="post-entry">
    <a href="http://dataphys.org/list/quickly-authoring-physical-visualizations/"><img class="list-view" width="170px" height="100px" src="http://dataphys.org/list/images/uploads/2014/11/photo-170x100@2x.jpg"></a>
    <div class="excerpt-listview">
      <p>
  
   Rahul Bhargava animates workshops where he has participants quickly build physical visualizations using raw material. One of the workshop&#39;s goals is to develop people&#39;s visual literacy.  Source: Rahul Bhargava (2013) Activities for Building Visual Literacy. datatherapy.wordpress.com. </p>
    </div>
    <div class="hidden full-text">   Rahul Bhargava animates workshops where he has participants quickly build physical visualizations using raw material. One of the workshop&#39;s goals is to develop people&#39;s visual literacy.  Source: Rahul Bhargava (2013) Activities for Building Visual Literacy. datatherapy.wordpress.com. </div>

  <div class="categories">
    <div class="categories tagi">
  Added by: <b>Pierre Dragicevic</b>.
  
    Category:
    
      <a
        href="http://dataphys.org/list/categories/enabling-technology/"
        >Enabling technology</a
      >&nbsp;
    
  
  
    Tags:
    <a
        href="http://dataphys.org/list/tags/authoring/"
        >authoring</a>, <a
        href="http://dataphys.org/list/tags/visual-literacy/"
        >visual literacy</a>
  
</div>

  </div><br><hr class="entry-main">
    </div>

</article>

            
                <article class="entry-main post category-enabling-technology">
  <a href="http://dataphys.org/list/create-your-own-sound-sculpture/">
    <h1 class="post-title">2015 – Create your own Sound Sculpture</h1>
  </a>
  <div class="post-entry">
    <a href="http://dataphys.org/list/create-your-own-sound-sculpture/"><img class="list-view" width="170px" height="100px" src="http://dataphys.org/list/images/uploads/2016/03/FA7XG62HFD1910K.RECT2100-170x100@2x.jpg"></a>
    <div class="excerpt-listview">
      <p>
  
    This Rhinoscript/Grasshopper procedure creates a 3D printing of an audio file by translating the waves into 3D curves instead of displaying them in 2D, thus elabling the user to &#34;feel&#34; the sound.  Also see our other entries on sound.  Source: 3D Sound representation </p>
    </div>
    <div class="hidden full-text">    This Rhinoscript/Grasshopper procedure creates a 3D printing of an audio file by translating the waves into 3D curves instead of displaying them in 2D, thus elabling the user to &#34;feel&#34; the sound.  Also see our other entries on sound.  Source: 3D Sound representation </div>

  <div class="categories">
    <div class="categories tagi">
  Added by: <b>Jean Vanderdonckt</b>.
  
    Category:
    
      <a
        href="http://dataphys.org/list/categories/enabling-technology/"
        >Enabling technology</a
      >&nbsp;
    
  
  
    Tags:
    <a
        href="http://dataphys.org/list/tags/sound/"
        >sound</a>, <a
        href="http://dataphys.org/list/tags/sound-sculpture/"
        >sound sculpture</a>
  
</div>

  </div><br><hr class="entry-main">
    </div>

</article>

            
                <article class="entry-main post category-enabling-technology">
  <a href="http://dataphys.org/list/physical-globe-visualizations/">
    <h1 class="post-title">2017 – Fabricating Physical Globe Visualizations</h1>
  </a>
  <div class="post-entry">
    <a href="http://dataphys.org/list/physical-globe-visualizations/"><img class="list-view" width="170px" height="100px" src="http://dataphys.org/list/images/uploads/2020/06/Globe-6-170x100@2x.jpg"></a>
    <div class="excerpt-listview">
      <p>
  
    Geospatial datasets are too complex to easily visualize and understand on a computer screen. Combining digital fabrication with a discrete global grid system (DGGS) can produce physical models of the Earth for visualizing multiresolution geospatial datasets. This proposed approach includes a mechanism for attaching a set of 3D printed segments to produce a scalable model of the Earth. Two models have been produced that support the attachment of different datasets both in 2D and 3D format. [&hellip;]</p>
    </div>
    <div class="hidden full-text">    Geospatial datasets are too complex to easily visualize and understand on a computer screen. Combining digital fabrication with a discrete global grid system (DGGS) can produce physical models of the Earth for visualizing multiresolution geospatial datasets. This proposed approach includes a mechanism for attaching a set of 3D printed segments to produce a scalable model of the Earth. Two models have been produced that support the attachment of different datasets both in 2D and 3D format.  Also see our other entries on globe models and rearrangeable physical visualizations.  Source: Hessam Djavaherpour, Ali Mahdavi-Amiri, Faramarz F. Samavati (2017) Physical Visualization of Geospatial Datasets.  </div>

  <div class="categories">
    <div class="categories tagi">
  Added by: <b>Hessam Djavaherpour</b>.
  
    Category:
    
      <a
        href="http://dataphys.org/list/categories/enabling-technology/"
        >Enabling technology</a
      >&nbsp;
    
  
  
    Tags:
    <a
        href="http://dataphys.org/list/tags/3d-printing/"
        >3d printing</a>, <a
        href="http://dataphys.org/list/tags/cartographic/"
        >cartographic</a>, <a
        href="http://dataphys.org/list/tags/digital-fabrication/"
        >digital fabrication</a>, <a
        href="http://dataphys.org/list/tags/globe/"
        >globe</a>, <a
        href="http://dataphys.org/list/tags/rearrangeable/"
        >rearrangeable</a>
  
</div>

  </div><br><hr class="entry-main">
    </div>

</article>

            
                <article class="entry-main post category-enabling-technology">
  <a href="http://dataphys.org/list/landscaper/">
    <h1 class="post-title">2018 – Landscaper: 3D Printing and Assembling of Terrain Models</h1>
  </a>
  <div class="post-entry">
    <a href="http://dataphys.org/list/landscaper/"><img class="list-view" width="170px" height="100px" src="http://dataphys.org/list/images/uploads/2020/06/landscaper-170x100@2x.jpg"></a>
    <div class="excerpt-listview">
      <p>
  
    Landscape models of geospatial regions provide an intuitive mechanism for exploring complex geospatial information. However, the methods currently used to create these scale models require a large amount of resources, which restricts the availability of these models to a limited number of popular public places, such as museums and airports. Landscaper is a system for creating these physical models using an affordable 3D printer in order to make the creation of these models more widely [&hellip;]</p>
    </div>
    <div class="hidden full-text">    Landscape models of geospatial regions provide an intuitive mechanism for exploring complex geospatial information. However, the methods currently used to create these scale models require a large amount of resources, which restricts the availability of these models to a limited number of popular public places, such as museums and airports. Landscaper is a system for creating these physical models using an affordable 3D printer in order to make the creation of these models more widely accessible.  Also see our other entries on terrain modeling and terrain models.  Source: Kamyar Allahverdi, Hessam Djavaherpour, Ali Mahdavi-Amiri, Faramarz F. Samavati (2018) Landscaper: A Modeling System for 3D Printing Scale Models of Landscapes. </div>

  <div class="categories">
    <div class="categories tagi">
  Added by: <b>Hessam Djavaherpour</b>.
  
    Category:
    
      <a
        href="http://dataphys.org/list/categories/enabling-technology/"
        >Enabling technology</a
      >&nbsp;
    
  
  
    Tags:
    <a
        href="http://dataphys.org/list/tags/3d-printing/"
        >3d printing</a>, <a
        href="http://dataphys.org/list/tags/assembly/"
        >assembly</a>, <a
        href="http://dataphys.org/list/tags/digital-fabrication/"
        >digital fabrication</a>, <a
        href="http://dataphys.org/list/tags/terrain-model/"
        >terrain model</a>
  
</div>

  </div><br><hr class="entry-main">
    </div>

</article>

            
                <article class="entry-main post category-enabling-technology">
  <a href="http://dataphys.org/list/multimaterial-printing-of-volumetric-scientific-visualizations/">
    <h1 class="post-title">2018 – Multimaterial Printing of Volumetric Scientific Visualizations</h1>
  </a>
  <div class="post-entry">
    <a href="http://dataphys.org/list/multimaterial-printing-of-volumetric-scientific-visualizations/"><img class="list-view" width="170px" height="100px" src="http://dataphys.org/list/images/uploads/2018/06/115295-76-170x100@2x.jpg"></a>
    <div class="excerpt-listview">
      <p>
  
    Researchers from MIT Media Lab and Harvard University have developed a method for accurately physicalizing scientific visualizations using multimaterial 3D printers:   To fabricate an item on conventional 3D printers, one must make calculations regarding the object’s digital description, and then convert the resulting numeric description to geometric shapes which can be used to 3D print it. But the research team has developed a new technique to 3D print multimaterial data sets as physical [&hellip;]</p>
    </div>
    <div class="hidden full-text">    Researchers from MIT Media Lab and Harvard University have developed a method for accurately physicalizing scientific visualizations using multimaterial 3D printers:   To fabricate an item on conventional 3D printers, one must make calculations regarding the object’s digital description, and then convert the resulting numeric description to geometric shapes which can be used to 3D print it. But the research team has developed a new technique to 3D print multimaterial data sets as physical objects, which requires less pre-processing to create a more direct data-to-object translation, and builds a bridge between the physical and the digital.  ...  The technique actually negates the need to create an intermediate boundary representation of an object, which can end in information loss or data alteration for less ideal physical results.   Sources:   Sarah Saunders (2018) Researchers Develop Multimaterial Voxel-3D Printing Method For More Direct Data to Object Translation.   Christoph Bader et al. (2018) Making data matter: Voxel printing for the digital fabrication of data across scales and domains.   Images from chemeurope.com.   </div>

  <div class="categories">
    <div class="categories tagi">
  Added by: <b>Pierre Dragicevic</b>, sent by: <b>Arnold Platon</b>.
  
    Category:
    
      <a
        href="http://dataphys.org/list/categories/enabling-technology/"
        >Enabling technology</a
      >&nbsp;
    
  
  
    Tags:
    <a
        href="http://dataphys.org/list/tags/3d-printing/"
        >3d printing</a>, <a
        href="http://dataphys.org/list/tags/multimaterial/"
        >multimaterial</a>
  
</div>

  </div><br><hr class="entry-main">
    </div>

</article>

            
                <article class="entry-main post category-enabling-technology">
  <a href="http://dataphys.org/list/the-anatomical-edutainer/">
    <h1 class="post-title">2020 – The Anatomical Edutainer</h1>
  </a>
  <div class="post-entry">
    <a href="http://dataphys.org/list/the-anatomical-edutainer/"><img class="list-view" width="170px" height="100px" src="http://dataphys.org/list/images/uploads/2020/12/edutainer-170x100@2x.jpg"></a>
    <div class="excerpt-listview">
      <p>
  
    Physical visualizations (i.e., data representations by means of physical objects) have been used for many centuries in medical and anatomical education. Recently, 3D printing techniques started also to emerge. Still, other medical physicalizations that rely on affordable and easy-to-find materials are limited, while smart strategies that take advantage of the optical properties of our physical world have not been thoroughly investigated.  In our paper, which received the Best Short Paper [&hellip;]</p>
    </div>
    <div class="hidden full-text">    Physical visualizations (i.e., data representations by means of physical objects) have been used for many centuries in medical and anatomical education. Recently, 3D printing techniques started also to emerge. Still, other medical physicalizations that rely on affordable and easy-to-find materials are limited, while smart strategies that take advantage of the optical properties of our physical world have not been thoroughly investigated.  In our paper, which received the Best Short Paper Award at IEEE Vis 2020, we propose the Anatomical Edutainer, a workflow to guide the easy, accessible, and affordable generation of physicalizations for tangible, interactive anatomical edutainment. Our workflow consists of two main components:  (1) the generation of 2D printable physicalizations, which exhibit different visual properties (i.e., hues of the visible spectrum) under colored lenses or colored lights, and reveal distinct anatomical structures, and  (2) the generation of 3D foldable physicalizations, where anatomical structures undergo unfolding, to ensure that they can be printed and assembled to a 3D papercraft. The assembled papercraft can be subsequently explored under colored lenses or lights, similarly to its 2D counterpart.  Anyone with access to a computer and a common printer can create our proposed physicalizations, while the colored filters or lights are widely available and affordable. Additionally, the templates of our physicalizations need to be created only once and can be easily reprinted, which makes them an affordable and accessible tool for educational purposes, such as at art exhibitions or science museums. The tangible character of the 3D papercraft assembly adds to the enjoyment of the process, making them especially suitable for children’s anatomical edutainment.   Source: Renata Raidou (2020) https://renataraidou.com/anatomical-edutainer/ </div>

  <div class="categories">
    <div class="categories tagi">
  Added by: <b>Renata Raidou</b>.
  
    Category:
    
      <a
        href="http://dataphys.org/list/categories/enabling-technology/"
        >Enabling technology</a
      >&nbsp;
    
  
  
    Tags:
    <a
        href="http://dataphys.org/list/tags/anatomy/"
        >anatomy</a>
  
</div>

  </div><br><hr class="entry-main">
    </div>

</article>

            
                <article class="entry-main post category-enabling-technology">
  <a href="http://dataphys.org/list/slice-and-dice-a-physicalization-workflow-for-anatomical-edutainment/">
    <h1 class="post-title">2020 – Slice and Dice: A Physicalization Workflow for Anatomical Edutainment</h1>
  </a>
  <div class="post-entry">
    <a href="http://dataphys.org/list/slice-and-dice-a-physicalization-workflow-for-anatomical-edutainment/"><img class="list-view" width="170px" height="100px" src="http://dataphys.org/list/images/uploads/2020/12/IMG_20200917_102922-2-768x678-170x100@2x.jpg"></a>
    <div class="excerpt-listview">
      <p>
  
    During the last decades, anatomy has become an interesting topic in education—even for laymen or schoolchildren. As medical imaging techniques become increasingly sophisticated, virtual anatomical education applications have emerged. Still, anatomical models are often preferred, as they facilitate 3D localization of anatomical structures. Recently, data physicalizations have proven to be effective and engaging—sometimes, even more than their virtual counterparts. So far, medical data [&hellip;]</p>
    </div>
    <div class="hidden full-text">    During the last decades, anatomy has become an interesting topic in education—even for laymen or schoolchildren. As medical imaging techniques become increasingly sophisticated, virtual anatomical education applications have emerged. Still, anatomical models are often preferred, as they facilitate 3D localization of anatomical structures. Recently, data physicalizations have proven to be effective and engaging—sometimes, even more than their virtual counterparts. So far, medical data physicalizations involve mainly 3D printing, which is still expensive and cumbersome for laymen use.  In our paper, we investigate alternative forms of physicalizations, which use readily available technologies (home printers) and inexpensive materials (paper or semi-transparent films) to generate crafts for anatomical edutainment. To the best of our knowledge, this is the first computer-generated crafting approach within an anatomical edutainment context, which is based on volumetric medical imaging data.  Our approach follows a cost-effective, simple, and easy-to-employ workflow, resulting into assemblable data sculptures (i.e., semi-transparent sliceforms). It primarily supports volumetric data (such as CT or MRI), but mesh data can also be imported. An octree slices up the imported volume, considering a user-defined transfer function. Then, an optimization step simplifies the slice configuration and proposes the optimal order for easy assembly. Finally, a packing algorithm places the resulting slices with their labels, annotations, and assembly instructions on a paper or transparent film of user-selected size. This can be later printed, assembled into a sliceform, and explored. An initial assessment of our work demonstrated its value for the successful creation of interactive and engaging anatomical physicalizations.   Source: Renata Raidou (2020) https://renataraidou.com/slice-and-dice/ </div>

  <div class="categories">
    <div class="categories tagi">
  Added by: <b>Renata Raidou</b>.
  
    Category:
    
      <a
        href="http://dataphys.org/list/categories/enabling-technology/"
        >Enabling technology</a
      >&nbsp;
    
  
  
    Tags:
    <a
        href="http://dataphys.org/list/tags/anatomy/"
        >anatomy</a>
  
</div>

  </div><br><hr class="entry-main">
    </div>

</article>

            
                <article class="entry-main post category-enabling-technology">
  <a href="http://dataphys.org/list/venous-materials/">
    <h1 class="post-title">2020 – Venous Materials</h1>
  </a>
  <div class="post-entry">
    <a href="http://dataphys.org/list/venous-materials/"><img class="list-view" width="170px" height="100px" src="http://dataphys.org/list/images/uploads/2020/12/1SmSqW8oM4av4Kpma6qswRA-170x100@2x.jpeg"></a>
    <div class="excerpt-listview">
      <p>
  
  .   A team of researchers at the MIT Media Lab developed physical user interfaces based on fluidic channels that can interactively respond to mechanical inputs from the user, without any electrical power. Above, line charts that are activated and animated by pressure input.  Also see our other artifacts involving mechanical interaction and physical computation.  Source: Hila Mor, Yu Tianyu, Ken Nakagaki, Benjamin Harvey Miller, Yichen Jia, and Hiroshi Ishii (2020) Venous Materials: Towards [&hellip;]</p>
    </div>
    <div class="hidden full-text">  .   A team of researchers at the MIT Media Lab developed physical user interfaces based on fluidic channels that can interactively respond to mechanical inputs from the user, without any electrical power. Above, line charts that are activated and animated by pressure input.  Also see our other artifacts involving mechanical interaction and physical computation.  Source: Hila Mor, Yu Tianyu, Ken Nakagaki, Benjamin Harvey Miller, Yichen Jia, and Hiroshi Ishii (2020) Venous Materials: Towards interactive, fluidic mechanism. </div>

  <div class="categories">
    <div class="categories tagi">
  Added by: <b>Pierre Dragicevic</b>.
  
    Category:
    
      <a
        href="http://dataphys.org/list/categories/enabling-technology/"
        >Enabling technology</a
      >&nbsp;
    
  
  
    Tags:
    <a
        href="http://dataphys.org/list/tags/fluidic-channels/"
        >fluidic channels</a>, <a
        href="http://dataphys.org/list/tags/mechanical-interaction/"
        >mechanical interaction</a>, <a
        href="http://dataphys.org/list/tags/physical-computation/"
        >physical computation</a>
  
</div>

  </div><br><hr class="entry-main">
    </div>

</article>

            
                <article class="entry-main post category-enabling-technology">
  <a href="http://dataphys.org/list/physical-visualizations-of-the-future/">
    <h1 class="post-title">2025 – Digitally-Fabricated Visualizations of the Future</h1>
  </a>
  <div class="post-entry">
    <a href="http://dataphys.org/list/physical-visualizations-of-the-future/"><img class="list-view" width="170px" height="100px" src="http://dataphys.org/list/images/uploads/2014/11/xgen-cubes-1404303119812_3-6k_verge_super_wide-170x100@2x.jpg"></a>
    <div class="excerpt-listview">
      <p>
  
    These images have nothing to do with physical visualizations: they are not data-driven but abstract, and they are not even physical but instead photo-realistic computer-generated images. However, these images from digital artist Lee Griggs give an idea of what physical visualizations may look like in the near future once we overcome the limitations of today&#39;s digital fabrication technology: they will be visually and haptically elaborate, colorful, rich, and beautiful.  Make sure you look at [&hellip;]</p>
    </div>
    <div class="hidden full-text">    These images have nothing to do with physical visualizations: they are not data-driven but abstract, and they are not even physical but instead photo-realistic computer-generated images. However, these images from digital artist Lee Griggs give an idea of what physical visualizations may look like in the near future once we overcome the limitations of today&#39;s digital fabrication technology: they will be visually and haptically elaborate, colorful, rich, and beautiful.  Make sure you look at the full-res images.  Sources:   Colin Lecher (2014) This artist&#39;s colorful renderings look like Atlantis - Cities made from code.   Lee Griggs (2014) XGen rendered with Arnold for Maya.   </div>

  <div class="categories">
    <div class="categories tagi">
  Added by: <b>Pierre Dragicevic</b>, sent by: <b>Benjamin Bach</b>.
  
    Category:
    
      <a
        href="http://dataphys.org/list/categories/enabling-technology/"
        >Enabling technology</a
      >&nbsp;
    
  
  
    Tags:
    <a
        href="http://dataphys.org/list/tags/future/"
        >future</a>
  
</div>

  </div><br><hr class="entry-main">
    </div>

</article>

            
                <article class="entry-main post category-enabling-technology">
  <a href="http://dataphys.org/list/cetonia-drone-swarm-visualizations/">
    <h1 class="post-title">2033 – Cetonia: Drone Swarm Visualizations</h1>
  </a>
  <div class="post-entry">
    <a href="http://dataphys.org/list/cetonia-drone-swarm-visualizations/"><img class="list-view" width="170px" height="100px" src="http://dataphys.org/list/images/uploads/2014/11/Large-170x100@2x.png"></a>
    <div class="excerpt-listview">
      <p>
  
    As part of the VIS&#39;14 Workshop Death of the Desktop, infovis researcher Wesley Willett imagines how nano drone swarms may be used in 2033 both to capture and visualize data directly in the real world:   At barely 1.5 centimeters across, each Cetonia scarab is a marvel of precision engineering. Designed from the ground up for agile flight, their integrated hydrogen chambers and a high-efficiency hover mode permit 15+ minutes of air time between charges. The hueSHIFT carapace is capable of [&hellip;]</p>
    </div>
    <div class="hidden full-text">    As part of the VIS&#39;14 Workshop Death of the Desktop, infovis researcher Wesley Willett imagines how nano drone swarms may be used in 2033 both to capture and visualize data directly in the real world:   At barely 1.5 centimeters across, each Cetonia scarab is a marvel of precision engineering. Designed from the ground up for agile flight, their integrated hydrogen chambers and a high-efficiency hover mode permit 15&#43; minutes of air time between charges. The hueSHIFT carapace is capable of displaying over 22 million possible colors and provides clear visual feedback in day or night with visibilities up to 1.5 kilometers. Integrated camera and sensor arrays permit full 6D reconstructions with composition profiling. From your wrist or a personal field station you can quickly deploy flights in automated formations to survey, measure, record, and manipulate almost anything.   Source: Wesley Willett (2014) Cetonia - A Dynamic Swarm at your Fingertips. </div>

  <div class="categories">
    <div class="categories tagi">
  Added by: <b>Pierre Dragicevic</b>.
  
    Category:
    
      <a
        href="http://dataphys.org/list/categories/enabling-technology/"
        >Enabling technology</a
      >&nbsp;
    
  
  
    Tags:
    <a
        href="http://dataphys.org/list/tags/future/"
        >future</a>, <a
        href="http://dataphys.org/list/tags/nano-drones/"
        >nano drones</a>
  
</div>

  </div><br><hr class="entry-main">
    </div>

</article>

            
                <article class="entry-main post category-enabling-technology">
  <a href="http://dataphys.org/list/programmable-matter/">
    <h1 class="post-title">2060 – Programmable Matter</h1>
  </a>
  <div class="post-entry">
    <a href="http://dataphys.org/list/programmable-matter/"><img class="list-view" width="170px" height="100px" src="http://dataphys.org/list/images/uploads/2014/11/claytronics-170x100@2x.jpg"></a>
    <div class="excerpt-listview">
      <p>
  
     In 1965 Ivan Sutherland already mentioned programmable matter as the ultimate computer display:   The ultimate display would, of course, be a room within which the computer can control the existence of matter. A chair displayed in such a room would be good enough to sit in. Handcuffs displayed in such a room would be confining, and a bullet displayed in such a room would be fatal. With appropriate programming such a display could literally be the Wonderland into which Alice walked. [&hellip;]</p>
    </div>
    <div class="hidden full-text">     In 1965 Ivan Sutherland already mentioned programmable matter as the ultimate computer display:   The ultimate display would, of course, be a room within which the computer can control the existence of matter. A chair displayed in such a room would be good enough to sit in. Handcuffs displayed in such a room would be confining, and a bullet displayed in such a room would be fatal. With appropriate programming such a display could literally be the Wonderland into which Alice walked.   Several research labs have been exploring ways to implement programmable matter through nanoscale robotics. This line of research goes by many names: dynamic physical rendering, smart dust, synthetic reality, utility fog, radical atoms or programmable matter. Looking at current publications and demos, we are far from being there yet. But in a few decades, we will have physical displays that offer full control over their shape, color and other material properties. Cephalopods won&#39;t feel alone anymore.  With programmable matter, physical visualizations will be able to accomodate any data set, they will be fully dynamic and interactive, and will allow both data analysts and lay people to perform complex data exploration tasks. Plugins will be available that will let people play with several of the physical visualizations listed here, in their original physical form.  The two concept videos above show how some designers and scientists envision interaction with programmable matter in a 3D modelling context. The first one is from the Carnegie Mellon University, the second one is from the MIT Media Lab. Will programmable also be free floating, as we&#39;ve seen in movies?  Sources:   Sutherland (1965) The Ultimate Display.   Carnegie Mellon University (2004) Claytronics.   Hiroshi Ishii et al (2012) Radical Atoms: Beyond Tangible Bits, Toward Transformable Materials.   </div>

  <div class="categories">
    <div class="categories tagi">
  Added by: <b>Pierre Dragicevic</b>.
  
    Category:
    
      <a
        href="http://dataphys.org/list/categories/enabling-technology/"
        >Enabling technology</a
      >&nbsp;
    
  
  
    Tags:
    <a
        href="http://dataphys.org/list/tags/claytronics/"
        >claytronics</a>, <a
        href="http://dataphys.org/list/tags/future/"
        >future</a>, <a
        href="http://dataphys.org/list/tags/programmable-matter/"
        >programmable matter</a>, <a
        href="http://dataphys.org/list/tags/radical-atoms/"
        >radical atoms</a>
  
</div>

  </div><br><hr class="entry-main">
    </div>

</article>

            
        </div>

    </div>
</div>

    <footer>
  <div class="footer">
  <hr/>
      <span class="tweetfollow alignright">Get notified of new posts: <div class="twitter-icon"><a href="https://twitter.com/dataphys"><img src="http://dataphys.org/list/images/Twitter_Logo_Blue.png"></a></div></span>

      <div class="license">
            <div class="alignleft cc-image"><a href="http://creativecommons.org/licenses/by-sa/3.0/" style="text-decoration: none;"><img alt="" src="http://i.creativecommons.org/l/by-sa/3.0/88x31.png" /></a></div>
            
            <div class="alignleft views-expressed">
              <span>The views expressed on this page are not necessarily the views of the curators and of their respective institutions.  This collection is <a href="http://creativecommons.org/licenses/by-sa/3.0/" style="text-decoration: none;">CC-BY-SA</a>. If you reuse or adapt it, please reference this page. <a href="javascript:;" onclick="toggle_visibility('bibtex');">See BibTeX</a> for citing.</span>
            
              <div id="bibtex" style="display:none;">
                <div class="code">    
    @Misc{physlist,
        Title                    = {List of Physical Visualizations},
        Author                   = {Dragicevic, Pierre and Jansen, Yvonne},
        HowPublished             = {\href{http://www.dataphys.org/list}{www.dataphys.org/list}},
        Note                     = {Last accessed <span id="bibtex-date"></span>},
        Year                     = {2012}
      }</div>
              </div>
          </div>

      </div>
    
  </div>

</div>
<script src="https://code.jquery.com/jquery-3.6.0.slim.min.js"></script>
  
<script src="http://dataphys.org/list/js/footer.js"></script>
</footer>

  </body>
</html>
