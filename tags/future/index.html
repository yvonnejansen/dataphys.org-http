<!DOCTYPE html>
<html lang="en-us">
  <head>
    <meta charset="utf-8" />
<title>future</title>


  
    
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-55415265-1"></script>
    <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());
    gtag('config', 'UA-55415265-1');
  </script>
  



<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1.0" />
<link
  rel="alternate"
  type="application/rss+xml"
  href="http://dataphys.org/list/index.xml"
  title="List of Physical Visualizations"
/>
<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="future"/>
<meta name="twitter:description" content=""/>



  <link rel="stylesheet" href="http://dataphys.org/list/css/style.css" />
  <link rel="preconnect" href="https://fonts.gstatic.com">
  <link href="https://fonts.googleapis.com/css2?family=Open+Sans:wght@300;400;600&display=swap" rel="stylesheet">

  </head>
  <body>
      <header>
    <div class="head">
      
      <a href="http://dataphys.org/list/">
        <center>
          List of Physical Visualizations<br />
      
        <div class="head2">and Related Artifacts</div>
      </center></a>
    </div>

  </header>
  


    
  <div class="container" role="main">
    <div class="content listview">
    <center><div class="head_query">Tag: future</div></center>
      
        
      

      
        <article class="entry-main post category-enabling-technology">
  <a href="http://dataphys.org/list/physical-visualizations-of-the-future/">
    <h1 class="post-title">2025 – Digitally-Fabricated Visualizations of the Future</h1>
  </a>
  <div class="post-entry">

    <a href="http://dataphys.org/list/physical-visualizations-of-the-future/">
    
      <img class="list-view" width="170px" height="100px" src="http://dataphys.org/list/images/uploads/2014/11/xgen-cubes-1404303119812_3-6k_verge_super_wide-170x100@2x.jpg">     
      
    </a>
    <div class="excerpt-listview">
      <p>
  
 These images have nothing to do with physical visualizations: they are not data-driven but abstract, and they are not even physical but instead photo-realistic computer-generated images. However, these images from digital artist Lee Griggs give an idea of what physical visualizations may look like in the near future once we overcome the limitations of today&#39;s digital fabrication technology: they will be visually and haptically elaborate, colorful, rich, and beautiful. Make sure you look at the [&hellip;]</p>
    </div>
    <div class="hidden full-text"> These images have nothing to do with physical visualizations: they are not data-driven but abstract, and they are not even physical but instead photo-realistic computer-generated images. However, these images from digital artist Lee Griggs give an idea of what physical visualizations may look like in the near future once we overcome the limitations of today&#39;s digital fabrication technology: they will be visually and haptically elaborate, colorful, rich, and beautiful. Make sure you look at the full-res images. Sources: Colin Lecher (2014) This artist&#39;s colorful renderings look like Atlantis - Cities made from code. Lee Griggs (2014) XGen rendered with Arnold for Maya. </div>

  <div class="categories">
    <div class="categories tagi">
  Added by: <b>Pierre Dragicevic</b>, sent by: <b>Benjamin Bach</b>.
  
    Category:
    
      <a
        href="http://dataphys.org/list/categories/enabling-technology/"
        >Enabling technology</a
      >&nbsp;
    
  
  
    Tags:
    <a
        href="http://dataphys.org/list/tags/future/"
        >future</a>
  
</div>

  </div><br><hr class="entry-main">
    </div>

</article>

      
        <article class="entry-main post category-enabling-technology">
  <a href="http://dataphys.org/list/cetonia-drone-swarm-visualizations/">
    <h1 class="post-title">2033 – Cetonia: Drone Swarm Visualizations</h1>
  </a>
  <div class="post-entry">

    <a href="http://dataphys.org/list/cetonia-drone-swarm-visualizations/">
    
      <img class="list-view" width="170px" height="100px" src="http://dataphys.org/list/images/uploads/2014/11/Large-170x100@2x.png">     
      
    </a>
    <div class="excerpt-listview">
      <p>
  
 As part of the VIS&#39;14 Workshop Death of the Desktop, infovis researcher Wesley Willett imagines how nano drone swarms may be used in 2033 both to capture and visualize data directly in the real world: At barely 1.5 centimeters across, each Cetonia scarab is a marvel of precision engineering. Designed from the ground up for agile flight, their integrated hydrogen chambers and a high-efficiency hover mode permit 15+ minutes of air time between charges. The hueSHIFT carapace is capable of [&hellip;]</p>
    </div>
    <div class="hidden full-text"> As part of the VIS&#39;14 Workshop Death of the Desktop, infovis researcher Wesley Willett imagines how nano drone swarms may be used in 2033 both to capture and visualize data directly in the real world: At barely 1.5 centimeters across, each Cetonia scarab is a marvel of precision engineering. Designed from the ground up for agile flight, their integrated hydrogen chambers and a high-efficiency hover mode permit 15&#43; minutes of air time between charges. The hueSHIFT carapace is capable of displaying over 22 million possible colors and provides clear visual feedback in day or night with visibilities up to 1.5 kilometers. Integrated camera and sensor arrays permit full 6D reconstructions with composition profiling. From your wrist or a personal field station you can quickly deploy flights in automated formations to survey, measure, record, and manipulate almost anything. Source: Wesley Willett (2014) Cetonia - A Dynamic Swarm at your Fingertips. </div>

  <div class="categories">
    <div class="categories tagi">
  Added by: <b>Pierre Dragicevic</b>.
  
    Category:
    
      <a
        href="http://dataphys.org/list/categories/enabling-technology/"
        >Enabling technology</a
      >&nbsp;
    
  
  
    Tags:
    <a
        href="http://dataphys.org/list/tags/future/"
        >future</a>, <a
        href="http://dataphys.org/list/tags/nano-drones/"
        >nano drones</a>
  
</div>

  </div><br><hr class="entry-main">
    </div>

</article>

      
        <article class="entry-main post category-enabling-technology">
  <a href="http://dataphys.org/list/programmable-matter/">
    <h1 class="post-title">2060 – Programmable Matter</h1>
  </a>
  <div class="post-entry">

    <a href="http://dataphys.org/list/programmable-matter/">
    
      <img class="list-view" width="170px" height="100px" src="http://dataphys.org/list/images/uploads/2014/11/claytronics-170x100@2x.jpg">     
      
    </a>
    <div class="excerpt-listview">
      <p>
  
 In 1965 Ivan Sutherland already mentioned programmable matter as the ultimate computer display: The ultimate display would, of course, be a room within which the computer can control the existence of matter. A chair displayed in such a room would be good enough to sit in. Handcuffs displayed in such a room would be confining, and a bullet displayed in such a room would be fatal. With appropriate programming such a display could literally be the Wonderland into which Alice walked. Several [&hellip;]</p>
    </div>
    <div class="hidden full-text"> In 1965 Ivan Sutherland already mentioned programmable matter as the ultimate computer display: The ultimate display would, of course, be a room within which the computer can control the existence of matter. A chair displayed in such a room would be good enough to sit in. Handcuffs displayed in such a room would be confining, and a bullet displayed in such a room would be fatal. With appropriate programming such a display could literally be the Wonderland into which Alice walked. Several research labs have been exploring ways to implement programmable matter through nanoscale robotics. This line of research goes by many names: dynamic physical rendering, smart dust, synthetic reality, utility fog, radical atoms or programmable matter. Looking at current publications and demos, we are far from being there yet. But in a few decades, we will have physical displays that offer full control over their shape, color and other material properties. Cephalopods won&#39;t feel alone anymore. With programmable matter, physical visualizations will be able to accomodate any data set, they will be fully dynamic and interactive, and will allow both data analysts and lay people to perform complex data exploration tasks. Plugins will be available that will let people play with several of the physical visualizations listed here, in their original physical form. The two concept videos above show how some designers and scientists envision interaction with programmable matter in a 3D modelling context. The first one is from the Carnegie Mellon University, the second one is from the MIT Media Lab. Will programmable also be free floating, as we&#39;ve seen in movies? Sources: Sutherland (1965) The Ultimate Display. Carnegie Mellon University (2004) Claytronics. Hiroshi Ishii et al (2012) Radical Atoms: Beyond Tangible Bits, Toward Transformable Materials. </div>

  <div class="categories">
    <div class="categories tagi">
  Added by: <b>Pierre Dragicevic</b>.
  
    Category:
    
      <a
        href="http://dataphys.org/list/categories/enabling-technology/"
        >Enabling technology</a
      >&nbsp;
    
  
  
    Tags:
    <a
        href="http://dataphys.org/list/tags/claytronics/"
        >claytronics</a>, <a
        href="http://dataphys.org/list/tags/future/"
        >future</a>, <a
        href="http://dataphys.org/list/tags/programmable-matter/"
        >programmable matter</a>, <a
        href="http://dataphys.org/list/tags/radical-atoms/"
        >radical atoms</a>
  
</div>

  </div><br><hr class="entry-main">
    </div>

</article>

      
    </div>
    
  </div>

    <footer>
  <div class="footer">
  <hr/>
      <span class="tweetfollow alignright">Get notified of new posts: <div class="twitter-icon"><a href="https://twitter.com/dataphys"><img src="http://dataphys.org/list/images/Twitter_Logo_Blue.png"></a></div></span>

      <div class="license">
            <div class="alignleft cc-image"><a href="http://creativecommons.org/licenses/by-sa/3.0/" style="text-decoration: none;"><img alt="" src="http://i.creativecommons.org/l/by-sa/3.0/88x31.png" /></a></div>
            
            <div class="alignleft views-expressed">
              <span>The views expressed on this page are not necessarily the views of the curators and of their respective institutions.  This collection is <a href="http://creativecommons.org/licenses/by-sa/3.0/" style="text-decoration: none;">CC-BY-SA</a>. If you reuse or adapt it, please reference this page. <a href="javascript:;" onclick="toggle_visibility('bibtex');">See BibTeX</a> for citing.</span>
            
              <div id="bibtex" style="display:none;">
                <div class="code">    
    @Misc{physlist,
        Title                    = {List of Physical Visualizations},
        Author                   = {Dragicevic, Pierre and Jansen, Yvonne},
        HowPublished             = {\href{http://www.dataphys.org/list}{www.dataphys.org/list}},
        Note                     = {Last accessed <span id="bibtex-date"></span>},
        Year                     = {2012}
      }</div>
              </div>
          </div>

      </div>
    
  </div>

</div>
<script src="https://code.jquery.com/jquery-3.6.0.slim.min.js"></script>
  
<script src="http://dataphys.org/list/js/footer.js"></script>
</footer>

  </body>
</html>
